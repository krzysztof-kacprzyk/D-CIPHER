{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import scipy\n",
    "from utils._bootstrap import bootstrap, CONF\n",
    "import sympy\n",
    "\n",
    "VAR_NAME = \"D-CIPHER\"\n",
    "MSE_NAME = \"Abl. D-CIPHER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(equation, var_or_mse):\n",
    "    meta_reg = os.path.join(equation,var_or_mse,'*.p')\n",
    "    meta_files = glob.glob(meta_reg)\n",
    "    csv_files = [file.split('_meta.p')[0]+'_table.csv' for file in meta_files]\n",
    "    dfs = []\n",
    "    for meta_file, csv_file in zip(meta_files,csv_files):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        with open(meta_file, 'rb') as f:\n",
    "            setting = pickle.load(f)\n",
    "            args = setting['arguments']\n",
    "            gp_config = setting['gp_config']\n",
    "            df['name'] = args.name\n",
    "            df['equation_number'] = args.equation_number\n",
    "            df['width'] = args.width\n",
    "            df['frequency_per_dim'] = args.frequency_per_dim\n",
    "            df['noise_ratio'] = args.noise_ratio\n",
    "\n",
    "            if var_or_mse == 'var':\n",
    "                df['full_grid_samples'] = args.full_grid_samples\n",
    "                df['max_ind_basis'] = args.max_ind_basis\n",
    "                df['basis'] = args.basis\n",
    "            elif var_or_mse == 'mse':\n",
    "                df['diff_engine'] = args.diff_engine\n",
    "\n",
    "            df['conditions_set'] = args.conditions_set\n",
    "            df['num_trials'] = args.num_trials\n",
    "            df['normalization'] = args.normalization\n",
    "            df['solver'] = args.solver\n",
    "            df['global_seed'] = args.seed\n",
    "            df['num_samples'] = args.num_samples\n",
    "            df['source'] = setting['table']\n",
    "            for key in gp_config.keys():\n",
    "                if key not in ['function_set']:\n",
    "                    df[key] = gp_config[key]\n",
    "        dfs.append(df)    \n",
    "    full_df = pd.concat(dfs,ignore_index=True)\n",
    "    full_df.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most equations are checked for correctness by the program but some may be miscategorized.\n",
    "# This function allows for checking the correctness of equations according th the definition in Appendix E.8\n",
    "\n",
    "def evaluate_correct(df, exprs, verbose=False):\n",
    "    new_df = df.copy()\n",
    "    for index, row in new_df.iterrows():\n",
    "        truth_list = []\n",
    "        eqC = row['eqC']\n",
    "        for expr in exprs:\n",
    "            truth_list.append(eqC == expr)\n",
    "        if np.sum(truth_list) > 0:\n",
    "            if (new_df.loc[index,'is_correct'] == False) and verbose:\n",
    "                print(f\"Changed to true: {eqC}\")\n",
    "            new_df.loc[index,'is_correct'] = True\n",
    "        else:\n",
    "            if (new_df.loc[index,'is_correct'] == True) and verbose:\n",
    "                print(f\"Changed to false: {eqC}\")\n",
    "            new_df.loc[index,'is_correct'] = False\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function generates all equivalent functional forms of the given equation based on the given substitution dictionary as in Appendix E.8\n",
    "\n",
    "X0,X1,X2,X3 = sympy.symbols('X0,X1,X2,X3',real=True)\n",
    "C,C0,C1,C2,C3,C4,C5 = sympy.symbols('C,C0,C1,C2,C3,C4,C5')\n",
    "\n",
    "import itertools\n",
    "def generate_expr_list(f,sub_dict):\n",
    "    keys, values = zip(*sub_dict.items())\n",
    "    sub_variant_list = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "    expr_list = []\n",
    "    for sub_variant in sub_variant_list:\n",
    "        g = f\n",
    "        for key in sub_variant.keys():\n",
    "            g = g.subs(key,sub_variant[key])\n",
    "        expr_list.append(str(g))\n",
    "    return expr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed to true: -X2*exp(C*X1)\n",
      "Changed to true: -X2*exp(C*X1)\n",
      "Changed to true: -X2*exp(C*X1)\n",
      "Changed to true: -X2*exp(C*X1)\n",
      "Changed to true: -X2*exp(C*X1)\n",
      "Changed to true: -X2*exp(C*X1)\n",
      "Changed to true: -X2*exp(C*X1)\n",
      "Changed to true: -X2*exp(C*X1)\n",
      "Changed to true: -X2*exp(C*X1)\n",
      "Changed to true: -X2*exp(C*X1)\n",
      "Changed to true: -X2*exp(C*X1)\n"
     ]
    }
   ],
   "source": [
    "slm_var_df = combine('../results/SLM','var')\n",
    "slm_mse_df = combine('../results/SLM','mse')\n",
    "\n",
    "f = -(C0*X2 + C1) * sympy.exp(C2*X1+C3) + C4\n",
    "sub_dict = {\n",
    "    C0:[1,C],\n",
    "    C1:[0,C,-C],\n",
    "    C2:[1,C],\n",
    "    C3:[0,C,-C],\n",
    "    C4:[0,C,-C]\n",
    "}\n",
    "\n",
    "expr_list = generate_expr_list(f,sub_dict)\n",
    "\n",
    "slm_var_df = evaluate_correct(slm_var_df,expr_list,verbose=True)\n",
    "slm_mse_df = evaluate_correct(slm_mse_df,expr_list,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucess Probability\n",
      "             D-CIPHER  D-CIPHER std   Ablated  Ablated std\n",
      "noise_ratio                                               \n",
      "0.001        0.007047      0.000757  0.016721     0.000922\n",
      "0.010        0.007595      0.001180  0.016523     0.000787\n"
     ]
    }
   ],
   "source": [
    "num_operators = 5\n",
    "noise_ratios = [0.001,0.01]\n",
    "conf = CONF\n",
    "means = {}\n",
    "stds_res = {}\n",
    "\n",
    "for ind, df in enumerate([slm_var_df,slm_mse_df]):\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row['operator_0'] < 0:\n",
    "            signs = np.ones(num_operators) * -1\n",
    "        else:\n",
    "            signs = np.ones(num_operators) \n",
    "        df.loc[index,'error'] = 0.0\n",
    "        for i in range(num_operators):\n",
    "            df.loc[index,'error'] += (df.loc[index,f'operator_{i}'] - signs[i]*df.loc[index,f'target_weights_{i}']) ** 2\n",
    "        df.loc[index,'error'] = np.sqrt(df.loc[index,'error']/num_operators)\n",
    "    \n",
    "    ints = [bootstrap(df.loc[df['noise_ratio'] == noise_ratio,f\"error\"].to_numpy(float).reshape(1,-1),np.mean,vectorized=True,confidence_level=conf).confidence_interval for noise_ratio in noise_ratios]\n",
    "    stds = [bootstrap(df.loc[df['noise_ratio'] == noise_ratio,f\"error\"].to_numpy(float).reshape(1,-1),np.mean,vectorized=True,confidence_level=conf).standard_error for noise_ratio in noise_ratios]\n",
    "\n",
    "    lows = [i.low for i in ints]\n",
    "    highs = [i.high for i in ints]\n",
    "\n",
    "\n",
    "    means[f\"{'var' if ind == 0 else 'mse'}\"] = df.groupby('noise_ratio')[f\"error\"].mean()\n",
    "    stds_res[f\"{'var' if ind == 0 else 'mse'}\"] = stds\n",
    "\n",
    "result_df = pd.merge(means['var'],means['mse'],on='noise_ratio',suffixes=('_var','_mse'))\n",
    "result_df['std_var'] = stds_res['var']\n",
    "result_df['std_mse'] = stds_res['mse']\n",
    "\n",
    "result_df.columns = ['D-CIPHER','Ablated','D-CIPHER std','Ablated std']\n",
    "result_df = result_df[['D-CIPHER','D-CIPHER std','Ablated','Ablated std']]\n",
    "\n",
    "print(\"Sucess Probability\")\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE\n",
      "             D-CIPHER  D-CIPHER std  Ablated  Ablated std\n",
      "noise_ratio                                              \n",
      "0.001             0.6      0.154919      0.2     0.126491\n",
      "0.010             0.5      0.158114      0.2     0.126491\n"
     ]
    }
   ],
   "source": [
    "z = norm.ppf(1 - (1-CONF)/2)\n",
    "var = slm_var_df.groupby('noise_ratio')['is_correct']\n",
    "mse = slm_mse_df.groupby('noise_ratio')['is_correct']\n",
    "var_int = list(z*np.sqrt((var.mean() * (1-var.mean()))/var.count()))\n",
    "mse_int = list(z*np.sqrt((mse.mean() * (1-mse.mean()))/mse.count()))\n",
    "\n",
    "result_df = pd.merge(var.mean(),mse.mean(),on='noise_ratio',suffixes=('_var','_mse'))\n",
    "result_df['std_var'] = var_int\n",
    "result_df['std_mse'] = mse_int\n",
    "\n",
    "result_df.columns = ['D-CIPHER','Ablated','D-CIPHER std','Ablated std']\n",
    "result_df = result_df[['D-CIPHER','D-CIPHER std','Ablated','Ablated std']]\n",
    "\n",
    "print(\"Average RMSE\")\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d-cipher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
