{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import scipy\n",
    "from utils._bootstrap import bootstrap\n",
    "import sympy\n",
    "\n",
    "VAR_NAME = \"D-CIPHER\"\n",
    "MSE_NAME = \"Abl. D-CIPHER\"\n",
    "CONF = 0.682689 # 1 sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(equation, var_or_mse):\n",
    "    meta_reg = os.path.join(equation,var_or_mse,'*.p')\n",
    "    meta_files = glob.glob(meta_reg)\n",
    "    csv_files = [file.split('_meta.p')[0]+'_table.csv' for file in meta_files]\n",
    "    dfs = []\n",
    "    for meta_file, csv_file in zip(meta_files,csv_files):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        with open(meta_file, 'rb') as f:\n",
    "            setting = pickle.load(f)\n",
    "            args = setting['arguments']\n",
    "            gp_config = setting['gp_config']\n",
    "            df['name'] = args.name\n",
    "            df['filed_index'] = args.field_index\n",
    "            df['width'] = args.width\n",
    "            df['frequency_per_dim'] = args.frequency_per_dim\n",
    "            df['noise_ratio'] = args.noise_ratio\n",
    "\n",
    "            if var_or_mse == 'var':\n",
    "                df['full_grid_samples'] = args.full_grid_samples\n",
    "                df['max_ind_basis'] = args.max_ind_basis\n",
    "                df['basis'] = args.basis\n",
    "            elif var_or_mse == 'mse':\n",
    "                df['diff_engine'] = args.diff_engine\n",
    "\n",
    "            df['conditions_set'] = args.conditions_set\n",
    "            df['num_trials'] = args.num_trials\n",
    "            df['normalization'] = args.normalization\n",
    "            df['solver'] = args.solver\n",
    "            df['global_seed'] = args.seed\n",
    "            df['num_samples'] = args.num_samples\n",
    "            df['source'] = setting['table']\n",
    "            for key in gp_config.keys():\n",
    "                if key not in ['function_set']:\n",
    "                    df[key] = gp_config[key]\n",
    "        dfs.append(df)    \n",
    "    full_df = pd.concat(dfs,ignore_index=True)\n",
    "    full_df.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, filter_dict):\n",
    "    mask_list = [df[key]==filter_dict[key] for key in filter_dict.keys()]\n",
    "    global_mask = np.all(mask_list,axis=0)\n",
    "    return df[global_mask]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function generates all equivalent functional forms of the given equation based on the given substitution dictionary as in Appendix E.8\n",
    "\n",
    "X0,X1,X2,X3 = sympy.symbols('X0,X1,X2,X3',real=True)\n",
    "C,C0,C1,C2,C3,C4,C5 = sympy.symbols('C,C0,C1,C2,C3,C4,C5')\n",
    "\n",
    "import itertools\n",
    "def generate_expr_list(f,sub_dict):\n",
    "    keys, values = zip(*sub_dict.items())\n",
    "    sub_variant_list = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "    expr_list = []\n",
    "    for sub_variant in sub_variant_list:\n",
    "        g = f\n",
    "        for key in sub_variant.keys():\n",
    "            g = g.subs(key,sub_variant[key])\n",
    "        expr_list.append(str(g))\n",
    "    return expr_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most equations are checked for correctness by the program but some may be miscategorized.\n",
    "# This function allows for checking the correctness of equations according th the definition in Appendix E.8\n",
    "\n",
    "def evaluate_correct(df, exprs, verbose=False):\n",
    "    new_df = df.copy()\n",
    "    for index, row in new_df.iterrows():\n",
    "        truth_list = []\n",
    "        eqC = row['eqC']\n",
    "        for expr in exprs:\n",
    "            truth_list.append(eqC == expr)\n",
    "        if np.sum(truth_list) > 0:\n",
    "            if (new_df.loc[index,'is_correct'] == False) and verbose:\n",
    "                print(f\"Changed to true: {eqC}\")\n",
    "            new_df.loc[index,'is_correct'] = True\n",
    "        else:\n",
    "            if (new_df.loc[index,'is_correct'] == True) and verbose:\n",
    "                print(f\"Changed to false: {eqC}\")\n",
    "            new_df.loc[index,'is_correct'] = False\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_success(var_df, mse_df, by, conf, default_dict = {'noise_ratio':0.01,'num_samples':10,'delta_t':0.1, 'global_seed':2}):\n",
    "    new_dict = default_dict.copy()\n",
    "    new_dict.pop(by, None)\n",
    "    var = filter_df(var_df,new_dict).groupby(by)['is_correct']\n",
    "    mse = filter_df(mse_df,new_dict).groupby(by)['is_correct']\n",
    "    z = norm.ppf(1 - (1-conf)/2)\n",
    "    var_int = list(z*np.sqrt((var.mean() * (1-var.mean()))/var.count()))\n",
    "    mse_int = list(z*np.sqrt((mse.mean() * (1-mse.mean()))/mse.count()))\n",
    "    \n",
    "    # result_df = pd.join(var.mean(),mse.mean(),on=by,suffixes=('_var','_mse'))\n",
    "    # rewrite using merge\n",
    "    result_df = pd.merge(var.mean(),mse.mean(),on=by,suffixes=('_var','_mse'))\n",
    "\n",
    "    result_df['var_int'] = var_int\n",
    "    result_df['mse_int'] = mse_int\n",
    "\n",
    "    result_df.columns = ['D-CIPHER','Ablated','D-CIPHER std','Ablated std']\n",
    "\n",
    "    result_df = result_df[['D-CIPHER','D-CIPHER std','Ablated','Ablated std']]\n",
    "    \n",
    "    return result_df\n",
    "    \n",
    "def table_operator_difference_bootstrap(var_df, mse_df, by,conf,num_operators, signs, default_dict = {'noise_ratio':0.01,'num_samples':10,'delta_t':0.1, 'global_seed':2}):\n",
    "    \n",
    "    new_dict = default_dict.copy()\n",
    "    new_dict.pop(by, None)\n",
    "    found_operator_columns = [f\"operator_{i}\" for i in range(num_operators)]\n",
    "\n",
    "    target_operator_columns = [f\"target_weights_{i}\" for i in range(num_operators)]\n",
    "    var_f = filter_df(var_df,new_dict).copy()\n",
    "    mse_f = filter_df(mse_df,new_dict).copy()\n",
    "    \n",
    "    var_f['diff'] = 0.0\n",
    "    for i in range(num_operators):\n",
    "        var_f['diff'] += (var_f[f'operator_{i}'] - signs[i]*var_f[f'target_weights_{i}']) ** 2\n",
    "    var_f['diff'] = np.sqrt(var_f['diff']/num_operators)\n",
    "    mse_f['diff'] = 0.0\n",
    "    for i in range(num_operators):\n",
    "        mse_f['diff'] += (mse_f[f'operator_{i}'] - mse_f[f'target_weights_{i}']) ** 2\n",
    "    mse_f['diff'] = np.sqrt(mse_f['diff']/num_operators)\n",
    "    \n",
    "    var = var_f\n",
    "    mse = mse_f\n",
    "\n",
    "    params = var[by].unique()\n",
    "    params.sort()\n",
    "    \n",
    "    var_res = [bootstrap(var[var[by] == param]['diff'].to_numpy(float).reshape(1,-1),np.mean,vectorized=True,confidence_level=conf) for param in params]\n",
    "    \n",
    "    var_stds = [i.standard_error for i in var_res]\n",
    "    var_lows = [i.confidence_interval.low for i in var_res]\n",
    "    var_highs = [i.confidence_interval.high for i in var_res]\n",
    "    \n",
    "    var_means = var.groupby(by)['diff'].mean()\n",
    "    \n",
    "    mse_res = [bootstrap(mse[mse[by] == param]['diff'].to_numpy(float).reshape(1,-1),np.mean,vectorized=True,confidence_level=conf) for param in params]\n",
    "    mse_stds = [i.standard_error for i in mse_res]\n",
    "    mse_lows = [i.confidence_interval.low for i in mse_res]\n",
    "    mse_highs = [i.confidence_interval.high for i in mse_res]\n",
    "    \n",
    "    mse_means = mse.groupby(by)['diff'].mean()\n",
    "\n",
    "    result_df = pd.merge(var_means,mse_means,on=by,suffixes=('_var','_mse'))\n",
    "    \n",
    "    result_df['var_int'] = var_stds\n",
    "    result_df['mse_int'] = mse_stds\n",
    "\n",
    "    result_df.columns = ['D-CIPHER','Ablated','D-CIPHER std','Ablated std']\n",
    "    result_df = result_df[['D-CIPHER','D-CIPHER std','Ablated','Ablated std']]\n",
    "    return result_df\n",
    "    # print(var_means.loc[params])\n",
    "    # print(var_stds)\n",
    "    \n",
    "    # print(mse_means.loc[params])\n",
    "    # print(mse_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success probability\n",
      "             D-CIPHER  D-CIPHER std  Ablated  Ablated std\n",
      "noise_ratio                                              \n",
      "0.05             0.64      0.067882     0.46     0.070484\n",
      "0.10             0.42      0.069800     0.20     0.056568\n",
      "0.20             0.12      0.045956     0.04     0.027713\n",
      "Average RMSE\n",
      "             D-CIPHER  D-CIPHER std   Ablated  Ablated std\n",
      "noise_ratio                                               \n",
      "0.05         0.152813      0.008604  0.181458     0.008725\n",
      "0.10         0.208963      0.007200  0.236291     0.008001\n",
      "0.20         0.244196      0.005549  0.273323     0.006535\n"
     ]
    }
   ],
   "source": [
    "var_heat_df = combine(\"../results/Heat5\",'var')\n",
    "mse_heat_df = combine(\"../results/Heat5\",'mse')\n",
    "f = C0*sympy.exp(C1*X0+C2) + C3\n",
    "sub_dict = {\n",
    "    C0:[1,C],\n",
    "    C1:[1,C],\n",
    "    C2:[0,C,-C],\n",
    "    C3:[0,C,-C],\n",
    "}\n",
    "expr_list = generate_expr_list(f,sub_dict)\n",
    "\n",
    "var_heat_df = evaluate_correct(var_heat_df,expr_list)\n",
    "mse_heat_df = evaluate_correct(mse_heat_df,expr_list)\n",
    "\n",
    "print(\"Success probability\")\n",
    "print(table_success(var_heat_df, mse_heat_df,'noise_ratio',CONF,default_dict={'noise_ratio':0.01,'num_samples':10, 'global_seed':2}))\n",
    "\n",
    "print(\"Average RMSE\")\n",
    "print(table_operator_difference_bootstrap(var_heat_df, mse_heat_df,'noise_ratio',CONF,5,[-1,-1,1,1,1],default_dict = {'noise_ratio':0.01,'num_samples':10, 'global_seed':2}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d-cipher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
